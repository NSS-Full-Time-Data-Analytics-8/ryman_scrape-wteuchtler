{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4441673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2751bd",
   "metadata": {},
   "source": [
    "checked /robots.txt on ryman.com, for user-agent * did not see /events in disallow, so I think I'm good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://ryman.com/events/'\n",
    "\n",
    "ryman = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c158de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e26893",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ryman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in class he did .content instead of .text (unicode vs byte).text gives you the response in Unicode, .content gives it to you in bytes, more on what any of that means here, if you wish to delve deep:\n",
    "# https://betterprogramming.pub/strings-unicode-and-bytes-in-python-3-everything-you-always-wanted-to-know-27dc02ff2686\n",
    "\n",
    "soup = BS(ryman.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because h2 is too far up to directly get title, trying a lower structure, a. \n",
    "# but because there are so many other a tags, need to specify class\n",
    "header = soup.findAll('a', attrs = {'class': 'tribe-event-url'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.findAll('a', attrs = {'class': 'tribe-event-url'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bb533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now title is much higher up in structure, than when i grabbed by h2\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef068875",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_header = header[0]\n",
    "print(type(first_header))\n",
    "first_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52091c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_header['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396130ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_title = [x.get('title') for x in header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = soup.findAll('time')\n",
    "print(type(date_time))\n",
    "date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches length for title tags which should be good?\n",
    "len(date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14984ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date_time = date_time[0]\n",
    "first_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date_time['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b64ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#could have done x.text instead of doing datetime\n",
    "date_time_ext = [x.get('datetime') for x in date_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee01263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_time_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(date_time_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tup = list(zip(header_title, date_time_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_shows = pd.DataFrame(list_tup, columns=['headliner', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaf7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_shows['date'] = ryman_shows['date_time'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4df050",
   "metadata": {},
   "outputs": [],
   "source": [
    " ryman_shows['time'] = ryman_shows['date_time'].str[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ce6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out here to bring back date_time combined\n",
    "ryman_shows = ryman_shows.drop('date_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_shows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf152e",
   "metadata": {},
   "source": [
    "## attempt at #4, applying scrape to multiple pages\n",
    "\n",
    "### another helpful scrape resource - https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# got this from - https://stackoverflow.com/questions/69546438/how-to-create-a-for-loop-when-scraping-multiple-pages-of-a-url\n",
    "pageCount = 6\n",
    "urls_list = []\n",
    "base = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged={}'\n",
    "\n",
    "for x in range(pageCount)[1:] :\n",
    "    urls_list.append(base.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_5 = [requests.get(x) for x in urls_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecd0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ryman_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168385ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5 = [BS(x.text) for x in ryman_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a432838",
   "metadata": {},
   "outputs": [],
   "source": [
    "headerall5 = [x.findAll('a', attrs = {'class': 'tribe-event-url'}) for x in soup5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ab0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(headerall5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1023a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember this is the headers for all 5 pages, but it is broken out\n",
    "# in a list of headers for each page as each value of list(as shown in \n",
    "# the above cell), so need to keep using loops to move through the lists\n",
    "headerall5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this wont work because .get wont work in a list, is there a way around this? fixed in below cell\n",
    "#header5_title = [x.get('title') for x in headerall5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.append will create list of lists for each webpage, .extend will make single list containing all webpages\n",
    "\n",
    "# in words, for each webpage in headerall5 list, make a list in header_list(new empty list) of results from x.get \n",
    "# webpage is the chosen variable name of headerall5 list, meaning each of the 5 webpages, and x is the variable of \n",
    "# each webpage, meaning the 20 'titles' per webpage.\n",
    "header_list = []\n",
    "\n",
    "for webpage in headerall5: \n",
    "    header_list.extend([x.get('title') for x in webpage])\n",
    "    \n",
    "header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(header_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc87e81",
   "metadata": {},
   "source": [
    "## get datetime for all 5 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtall5 = [x.findAll('time') for x in soup5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90802081",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtall5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = []\n",
    "\n",
    "for page in dtall5:\n",
    "    dt_list.extend([x.get('datetime') for x in page])\n",
    "    \n",
    "dt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd388af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rymanall_tup = list(zip(header_list, dt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows = pd.DataFrame(rymanall_tup, columns=['headliner', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b93b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows['date'] = ryman5_shows['date_time'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    " ryman5_shows['time'] = ryman5_shows['date_time'].str[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows = ryman5_shows.drop('date_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8584cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows['date'] = pd.to_datetime(ryman5_shows['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get nicer looking dates\n",
    "ryman5_shows['date'] = ryman5_shows['date'].dt.strftime('%A,%d,%B,%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman5_shows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b636b0",
   "metadata": {},
   "source": [
    "# Bonus 1 add opener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd10dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_all5 = [x.findAll('span', attrs = {'class': 'opener'}) for x in soup5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_all5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e884216",
   "metadata": {},
   "source": [
    "## before I try to get 5 pages of openers, I want to look at how to pull just one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f886317",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1 = soup.findAll('span', attrs = {'class': 'opener'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7104f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1first = opener_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1first.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1text = [x.text for x in opener_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f479805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should only be 20, why are there extra openers?! after looking, some have 2 openers, \n",
    "# and some have no openers...\n",
    "len(opener_1text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#could search above span, then do a loop to find only the first opener per span?\n",
    "opener_1up = soup.findAll('div', attrs = {'class': 'tribe-beside-image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1up_name = [x.find('span', attrs = {'class':'opener'}) for x in opener_1up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630936b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opener_1up_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf73500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now this only has 20, I think this got rid of the ones with 2 openers, \n",
    "# but Im not sure if there are any with no openers that may still be an issue?\n",
    "len(opener_1up_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because some are empty, i cant get the text for these so i can try using regex instead to \n",
    "# pick out the text i want in the next cell\n",
    "#opener_1up_text = [x.text for x in opener_1up_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff063d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start by looking at just one at a time\n",
    "opener_1up_name_first = opener_1up_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93840a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_1up_name_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i dont think this dtype works for regex\n",
    "type(opener_1up_name_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bafaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert this to string\n",
    "opener_1up_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c259515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this converts it to string\n",
    "opener_1up_string = []\n",
    "for x in opener_1up_name :\n",
    "    opener_1up_string.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ce3b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opener_1up_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(opener_1up_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ba923",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_string_1 = opener_1up_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c113126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now regex works!\n",
    "re.search('opener', opener_string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nope\n",
    "re.search('[\\\"opener\\\">][a*\\w][</span>]', opener_string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d12214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nope\n",
    "re.search('opener\\\">\\w\\a*', opener_string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd804024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# got it!\n",
    "re.search('>.*<', opener_string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search('>.*<', opener_string_1).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(re.search('>.*<', opener_string_1).group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b84cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#as you can see in the below cell this is not what i wanted, and this wont work with .group(0)\n",
    "# for some reason, so I still dont know how to get this to output matching text instead of match object\n",
    "opener_text = []\n",
    "for x in opener_1up_string :\n",
    "    opener_text.append(re.search('>(.*)<', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11520520",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_text[0].group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c25f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so with an if/else if oject type is No text (or whatever its called) print none\n",
    "# and if text is less than 4 print none\n",
    "for x in opener_text:\n",
    "    if x is not None:\n",
    "        print(len(x.group(0)))\n",
    "    else :\n",
    "        print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc521ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check around cell 64 in class recording for a fix to this \n",
    "for x in opener_text:\n",
    "    if x is not None:\n",
    "        for x in opener_1up_string :\n",
    "            opener_text.append(re.search('>(.*)<', x).group(1))\n",
    "    else :\n",
    "        print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8511d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
